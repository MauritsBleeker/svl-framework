dataset:
  name: 'f30k'
  root: "./src/datasets"
  img_path: "./src/datasets/f30k/flickr30k-images"
  annotation_file: 'dataset_flickr30k.json'
  annotation_path: "./src/datasets/annotations"
  captions_per_image: 5
  latent_target_file: 'f30k_latent_targets.p'
  vocab_path: './src/vocab'
  vocab_file: 'f30k_vocab.pkl'

experiment:
  wandb_project: 'contrastive-shortcuts-dev'
  entity: '<wand entity>'
  experiment_name: 'f30k-dev'
  wandb_dir: './src/out'
  out_dir: '.src/out'
  cache_dir: './src/out/cache'
  development: True
  store_best_validation_model: False

dataloader:
  batch_size: 32
  eval_batch_size: 16
  num_workers: 0
  crop_size: 224

criterion:
  name: 'infonce' # [infonce, triplet]
  temperature: 0.07 # If None (i.e., empty), use temperature from clip (if clip is trained)
  tune_temperature: True
  alpha: 0.2
  reconstruction_metric: 'cosine'
  ifm: # implicit feature modification (IFM)
    use_ifm: False
    epsilon: 0.1

reconstruction_constraint:
    use_constraint: False
    alpha: 0.90
    bound:  0.1
    start_val: 1.
    max: 100.

model:
  image_caption_encoder :
    name: "VSE" # [clip, VSE, BASE]
    model_name: "resnet152" # resnet152: VSE/BASE | RN50 / ViT-B/32 : clip
    train: True
    train_img_encoder: True
    train_cap_encoder: True # not used at the moment
    embed_dim: 1024
    word_dim: 300
    num_gru_layers: 1
    img_pooling: 'avg' # [attention, avg]
  target_decoder:
    decode_target: False
    reconstruction_dim: 768
    hidden_features: 1024

training:
  model_save_file: model_last.pth
  best_model_file: model_best.pth
  n_epochs: 5
  log_step: 100
  grad_clip: 2. # the initial value was 1.
  val_epochs: 1
  use_fp16: False

optimizer:
  name: 'adam'
  learning_rate: 2e-4
  weight_decay: 0.0
  warmup_steps: 0

shortcuts:
  use_shortcuts: False # set to True to use shortcuts
  n_digits: 6 # represents the number of images
  random_number: True
  training:
    on_image: True
    on_caption: True
  evaluation:
    on_image: False
    on_caption: False
  bits:
    use_bits: False
    n_bits: 8 # 8 matches batch size of 256, i.e. 2 ** 8 = 256
    random: True

lr_scheduler:
    name: 'stepLR' #[stepLR, cosine_annealing]
    step_size: 15
    gamma: 0.1
